#!/usr/bin/env bash
# Ëøô‰∏™ËÑöÊú¨Â±ïÁ§∫Â¶Ç‰ΩïÁî®‰∏çÂêåÁöÑÊ®°ÂûãËøêË°åÂÆûÈ™å

# ËÆæÁΩÆÂ∑•‰ΩúË∑ØÂæÑ
ROOTPATH=${ROOTPATH:-/mnt/shared-storage-user/yefei}
cd "$ROOTPATH/SparseFusion"

export HF_ENDPOINT=https://hf-mirror.com
export HF_HOME=$ROOTPATH/cache
export PATH="$ROOTPATH/miniconda3/envs/sparsefusion/bin:$PATH"

# ======== ÈÖçÁΩÆÂå∫Âüü ========
# ÈÄâÊã©ÊÇ®ÊÉ≥‰ΩøÁî®ÁöÑÊ®°ÂûãÁªÑÂêàÔºàÂèñÊ∂àÊ≥®ÈáäÊÇ®ÊÉ≥Ë¶ÅÁöÑÁªÑÂêàÔºâ

# ÊñπÊ°à1: 0.5BÂø´ÈÄüÂÆûÈ™åÔºàÊé®ËçêÁî®‰∫éË∞ÉËØïÔºâ
MODEL1="models/Qwen2.5-0.5B-Instruct"
MODEL2="models/Qwen2.5-Coder-0.5B-Instruct"

# ÊñπÊ°à2: 1.5B‰∏ì‰∏öÊ®°ÂûãÔºàÊõ¥Â•ΩÁöÑÊÄßËÉΩÔºâ
# MODEL1="models/Qwen2.5-Math-1.5B-Instruct"
# MODEL2="models/Qwen2.5-Coder-1.5B-Instruct"

# ÊñπÊ°à3: Êï∞Â≠¶‰∏ìÁî®ÁªÑÂêà
# MODEL1="models/Qwen2.5-Math-1.5B-Instruct"
# MODEL2="models/wizardmath_7b"

# ÊñπÊ°à4: Ê∑∑ÂêàËßÑÊ®°
# MODEL1="models/Qwen2.5-0.5B-Instruct"
# MODEL2="models/Qwen2.5-Math-1.5B-Instruct"

# ÂÖ∂‰ªñÂèÇÊï∞
GPUS_PER_NODE=${GPUS_PER_NODE:-1}
POP_SIZE=${POP_SIZE:-16}
TOTAL_FP=${TOTAL_FP:-100}

# ==========================

echo "=================================="
echo "üöÄ ÂêØÂä®Ê®°ÂûãËøõÂåñÂÆûÈ™å"
echo "=================================="
echo "Ê®°Âûã1: $MODEL1"
echo "Ê®°Âûã2: $MODEL2"
echo "GPUÊï∞Èáè: $GPUS_PER_NODE"
echo "ÁßçÁæ§Â§ßÂ∞è: $POP_SIZE"
echo "ÊÄªÂâçÂêë‰º†ÈÄíÊ¨°Êï∞: $TOTAL_FP"
echo "=================================="

if (( GPUS_PER_NODE > 1 )); then
  echo "‰ΩøÁî® torchrun Â§öGPUÊ®°Âºè"
  exec torchrun \
    --standalone \
    --nproc_per_node="${GPUS_PER_NODE}" \
    run_evolution.py \
    --model1_path "${MODEL1}" \
    --model2_path "${MODEL2}" \
    --pop_size "${POP_SIZE}" \
    --total_forward_passes "${TOTAL_FP}" \
    --use_sharded_archive \
    --archive_backend gpu \
    "$@"
else
  echo "‰ΩøÁî®ÂçïGPUÊ®°Âºè"
  exec python run_evolution.py \
    --model1_path "${MODEL1}" \
    --model2_path "${MODEL2}" \
    --pop_size "${POP_SIZE}" \
    --total_forward_passes "${TOTAL_FP}" \
    --use_sharded_archive \
    --archive_backend gpu \
    "$@"
fi







